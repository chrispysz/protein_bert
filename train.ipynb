{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "[]\n",
      "365194 training set records, 73032 validation set records, 73032 test set records.\n",
      "[2023_07_19-23:44:21] Training set: Filtered out 0 of 365194 (0.0%) records of lengths exceeding 40.\n",
      "[2023_07_19-23:44:24] Validation set: Filtered out 0 of 73032 (0.0%) records of lengths exceeding 40.\n",
      "Clearing gpu memory...\n",
      "[2023_07_19-23:44:24] Training the entire fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krzys\\anaconda3\\envs\\pbert\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer GlobalAttention has arguments ['n_heads', 'd_key', 'd_value']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/40\n",
      "11413/11413 [==============================] - ETA: 0s - loss: 0.0072WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "11413/11413 [==============================] - 3430s 300ms/step - loss: 0.0072 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "11413/11413 [==============================] - ETA: 0s - loss: 0.0027WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "11413/11413 [==============================] - 3354s 294ms/step - loss: 0.0027 - val_loss: 0.0023 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "11413/11413 [==============================] - ETA: 0s - loss: 0.0013WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "11413/11413 [==============================] - 3419s 300ms/step - loss: 0.0013 - val_loss: 0.0027 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "11413/11413 [==============================] - ETA: 0s - loss: 2.8496e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "11413/11413 [==============================] - 3361s 294ms/step - loss: 2.8496e-04 - val_loss: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 5/40\n",
      "11413/11413 [==============================] - ETA: 0s - loss: 3.0072e-05WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "11413/11413 [==============================] - 3364s 295ms/step - loss: 3.0072e-05 - val_loss: 0.0048 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krzys\\anaconda3\\envs\\pbert\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2283/2283 [==============================] - 164s 71ms/step\n",
      "Test-set performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># records</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model seq len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>73032</td>\n",
       "      <td>0.991017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>73032</td>\n",
       "      <td>0.991017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # records       AUC\n",
       "Model seq len                     \n",
       "42                 73032  0.991017\n",
       "All                73032  0.991017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72863</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  72863    9\n",
       "1     32  128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krzys\\anaconda3\\envs\\pbert\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./proteinbert_models/proteinBERT_full/6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./proteinbert_models/proteinBERT_full/6\\assets\n"
     ]
    }
   ],
   "source": [
    "MODEL = '6'\n",
    "BENCHMARKS_DIR = './train_sets/full_valid/' + MODEL\n",
    "BENCHMARK_NAME = 'bass_pb40'\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import gc\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.valid.csv' % BENCHMARK_NAME)\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True),\n",
    "    keras.callbacks.TensorBoard(log_dir = './logs', histogram_freq = 1, update_freq= 100)\n",
    "]\n",
    "\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "        seq_len = 42, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = False, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 0, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "\n",
    "# Evaluating the performance on the test-set\n",
    "\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \\\n",
    "        start_seq_len = 42, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "\n",
    "model=model_generator.create_model(seq_len=42)\n",
    "\n",
    "model.save(\"./proteinbert_models/proteinBERT_full/\"+ MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1b47329c1883ff5d7a507e00ede3d1ef26d004fddc76401b5829eb31794c5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
